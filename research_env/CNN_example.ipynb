{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3111270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ca0c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4885234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory_path = \"Data\"\n",
    "data_zipfile_name = \"archive.zip\"\n",
    "data_zipfile_path = os.path.join(data_directory_path, data_zipfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02c6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ZipFile(data_zipfile_path, \"r\") as zip_f:\n",
    "#     zip_f.extractall(\"Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6235274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\training_set\\training_set\n"
     ]
    }
   ],
   "source": [
    "target_data_dirs = [\"cats\", \"dogs\"]\n",
    "parent_directory = os.path.join(data_directory_path, \"training_set\")\n",
    "parent_directory = os.path.join(parent_directory, \"training_set\")\n",
    "print(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d38549",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAD_DATA_DIR = \"Bad_data\"\n",
    "os.makedirs(BAD_DATA_DIR, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd94e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding full path to the images and verifying the Images  \n",
    "\n",
    "for dirs in os.listdir(parent_directory):\n",
    "    full_path_data_dirs = os.path.join(parent_directory, dirs)\n",
    "    for img in os.listdir(full_path_data_dirs):\n",
    "        full_path_image = os.path.join(full_path_data_dirs, img)\n",
    "        try:\n",
    "            image = Image.open(full_path_image)\n",
    "            image.verify()\n",
    "#             print(f\"{full_path_image} --> is varified\")\n",
    "            \n",
    "        except Exception as e:\n",
    "#             print(f\"{full_path_image} --> is BAD\")\n",
    "            bad_data_path = os.path.join(BAD_DATA_DIR, img)\n",
    "            shutil.move(full_path_image, bad_data_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b76c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df4e08e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 files belonging to 2 classes.\n",
      "Using 6404 files for training.\n",
      "Found 8005 files belonging to 2 classes.\n",
      "Using 1601 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#  img_dataset_from_directory will take the parent directory path\n",
    "#  it will split the data set, resize the images \n",
    "\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    parent_directory,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 13,\n",
    "    image_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")\n",
    "\n",
    "valid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    parent_directory,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 13,\n",
    "    image_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2189470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  creating a unique name for log directory everytime\n",
    "\n",
    "def get_log_path(base_dir = os.path.join(\"log_CNN_example\", \"fit\")):\n",
    "    uniquename = time.asctime().replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    log_path = os.path.join(base_dir, uniquename)\n",
    "    print(f\"saving logs at: {log_path}\")\n",
    "    return log_path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c1da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving logs at: log_CNN_example\\fit\\Fri_May_10_124214_2024\n"
     ]
    }
   ],
   "source": [
    "log_dir = get_log_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "777c5191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3) tf.Tensor([0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#  train_ds will give images and label\n",
    "#  labels it will select from folder names \n",
    "#  .take(1) will take only 1 batch (32 pics)\n",
    "\n",
    "for imgs, labels in train_ds.take(1):\n",
    "    print(imgs.shape, labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d09396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 224, 224, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7bf83e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a file writer to see the images on tensor board\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(logdir = log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd3a2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_writer.as_default():\n",
    "    images = np.array(imgs)\n",
    "    \n",
    "    tf.summary.image(\"samples\", images.astype(\"uint8\"), max_outputs = 10, step = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef9a9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  lets do the data augmentation\n",
    "#  we can use tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "#  the other way is by adding a layer of augmetation\n",
    "\n",
    "AUG_STEPS = [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1)\n",
    "]\n",
    "\n",
    "data_aug_layer = tf.keras.Sequential(AUG_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3633e21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3) tf.Tensor([1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#  lets see the augmented images \n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    images = data_aug_layer(images)\n",
    "    print(images.shape, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c7b362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Run command in a command prompt --> tensorboard --logdir=\"./research_env/log_CNN_example\"\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(logdir = log_dir)\n",
    " \n",
    "with file_writer.as_default():\n",
    "    images = np.array(images)\n",
    "    \n",
    "    tf.summary.image(\"Augmented\", images.astype(\"uint8\"), max_outputs = 10, step = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19882cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other way is \n",
    "\n",
    "aug_train_ds = train_ds.map(lambda x, y : (data_aug_layer(x, training = True), y))\n",
    "#  training = True will change the x in place "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e6fbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size = 32)\n",
    "valid_ds = valid_ds.prefetch(buffer_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6afab356",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS = [\n",
    "    tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), activation = \"relu\", input_shape = (224, 224, 3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size = (2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), activation = \"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size = (2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units = 128, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(units = 2, activation = \"softmax\")]\n",
    "\n",
    "    \n",
    "\n",
    "classifier = tf.keras.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1611228b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 93312)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               11944064  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11954466 (45.60 MB)\n",
      "Trainable params: 11954466 (45.60 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
